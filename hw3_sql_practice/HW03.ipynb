{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IMT 563 Winter 2021  #\n",
    "# Homework 03 - Advanced SQL in Python  #\n",
    "# Nicholas Marangi  #\n",
    "\n",
    "#################################### READ ME ##################################################################################################################################################################\n",
    "### The answers to these queries will different to those in the SQL page; this is primarily due to the fact that I downloaded a small subset of the total database. \n",
    "### In some cases, the Python and R answers will be subsets of the SQL equivalents; in others they will be entirely different\n",
    "\n",
    "########## Pandas and SQL Differences\n",
    "### 1. A lot of changes permanently affect the tables rather than creating temporary ones to show results like in SQL (normally not an issue but it is here), so I sometimes create a copy of each original table that would be altered by using copy()\n",
    "### 2. Often when we use CTEs in SQL (at least in the problem set), we are aggregating multiple records in a group; there's quite often a groupby clause, which helps in keeping the resultant records distinct. Pandas doesn't do this, so it sometimes requires the use of drop_duplicates() to accomplish that task\n",
    "##############################################################################################################################################################################################################\n",
    "\n",
    "# Q0. Import and preparation\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "city = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/City.csv\")\n",
    "country = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/Countries.csv\")\n",
    "custcat = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/CustomerCategories.csv\")\n",
    "cust = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/Customers.csv\")\n",
    "ordline = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/OrderLines.csv\")\n",
    "orders = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/Orders.csv\")\n",
    "peop = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/People.csv\")\n",
    "purordline = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/PurchaseOrderLines.csv\")\n",
    "purord = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/PurchaseOrders.csv\")\n",
    "st = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/StateProvinces.csv\")\n",
    "stockit = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/StockItems.csv\")\n",
    "supp = pd.read_csv(\"../../Codework/DataSets/WWI_SubDB/Suppliers.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q1. List the FullName, PreferredName, and number of people with the same preferred name of each person. # \n",
    "\n",
    "# Create NumPeopleWithPreferredName column -- DO NOT USE count() function; the combination of those below do far better\n",
    "peop_temp = peop.copy()\n",
    "peop_temp['NumPeopleWithPreferredName'] = peop_temp.groupby('PreferredName')['PreferredName'].transform('size')\n",
    "\n",
    "# Order the results by FullName; Only select the attributes mentioned in the question prompt; limit the results to 30\n",
    "peop_temp.sort_values('FullName')[['FullName','PreferredName','NumPeopleWithPreferredName']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q2. List the CustomerName, CityName, and the number of customers who share the same city, filter for all customers with 2 or more customers in the same city. # \n",
    "\n",
    "# Rename DeliveryCityID column in Customers to CityID; merge() needs for the 'on' parameter to have matching names\n",
    "temp_cust = cust.copy()\n",
    "\n",
    "temp_cust.rename(columns={'DeliveryCityID':'CityID'}, inplace=True)\n",
    "join = temp_cust.merge(city, on = 'CityID')\n",
    "\n",
    "# Create NumCustomersSharingCity column\n",
    "join['NumCustomersSharingCity'] = join.groupby('CityID')['CustomerName'].transform('size')\n",
    "\n",
    "# Filter by NumCustomersSharingCity being >= 2, also only select the attributes mentioned in the question\n",
    "join[['CustomerName','CityName','NumCustomersSharingCity']][join['NumCustomersSharingCity'] >= 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. List the CustomerName, CityName, StateProvinceName, CustomersPerState, LatestRecordedPopulation of the city and the ranking of each city’s population within # \n",
    "#     its given StateProvince from highest to lowest city population. # \n",
    "\n",
    "###### PREP & JOINS #######\n",
    "city_temp = city.copy()\n",
    "cust_temp = cust.copy()\n",
    "\n",
    "city_temp.rename(columns={'LatestRecordedPopulation':'LatestRecordedCityPopulation'}, inplace=True)\n",
    "cust_temp.rename(columns={'DeliveryCityID':'CityID'}, inplace=True)\n",
    "\n",
    "# Begin joins -- inner join b/w cust and city sheds many records b/c both are subsets of the WWI database\n",
    "join = cust_temp.merge(city_prep, on = 'CityID').merge(st, on = 'StateProvinceID')\n",
    "\n",
    "# Create appropriate attributes\n",
    "join['CustomersPerState'] = join.groupby(\"StateProvinceID\")['CustomerName'].transform('size')\n",
    "join['CityPopulationRank'] = join.groupby('StateProvinceID')['LatestRecordedCityPopulation'].rank(method = 'min', ascending = False)\n",
    "\n",
    "join[['CustomerName','CityName','StateProvinceName','CustomersPerState','LatestRecordedCityPopulation','CityPopulationRank']].sort_values(['StateProvinceName','CityPopulationRank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q4. List the StockItemname, UnitPrice, TypicalWeightPerUnit, and the Ranking of highest UnitPrice, returning only the top 10 stock items by rank. # \n",
    "\n",
    "###### PREP & JOINS #######\n",
    "join = stockit.merge(ordline, on = 'StockItemID')\n",
    "\n",
    "# There are duplicates in this that wouldn't exist in the SQL query b/c python treats the table query as SELECT * whereas Azure modifies the results based on the SQL query\n",
    "# This mess of code ended up working, but I doubt that it's the optimal solution to the problem\n",
    "\n",
    "# Selected the attributes and dropped duplicate records\n",
    "join = join[['StockItemName','UnitPrice_x','TypicalWeightPerUnit']].drop_duplicates()\n",
    "# Sort by UnitPrice\n",
    "join = join.sort_values('UnitPrice_x', ascending = False)\n",
    "# Create RankHighestUnitPrice attribute by grabbing UnitPrice and ranking it\n",
    "join['RankHighestUnitPrice'] = join['UnitPrice_x'].rank(ascending = False)\n",
    "# Due to the unique way this program ranks (i.e. ties are averaged), we have a significantly different result\n",
    "join[join['RankHighestUnitPrice'] <= 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q5. List the SalesPersonFullName, CustomerName, CityName, OrderDate, and the number of Orders that the given Salesperson was a part of for the given year (2014) # \n",
    "#     and month (6).\n",
    "\n",
    "###### PREP & JOINS #######\n",
    "peop_temp = peop.copy()\n",
    "cust_temp = cust.copy()\n",
    "\n",
    "peop_temp.rename(columns = {'PersonID':'SalespersonPersonID'}, inplace = True)\n",
    "cust_temp.rename(columns={'DeliveryCityID':'CityID'}, inplace=True)\n",
    "\n",
    "\n",
    "join = peop_temp.merge(orders, on = 'SalespersonPersonID').merge(cust_temp, on = 'CustomerID').merge(city, on = 'CityID')\n",
    "\n",
    "# Filter by designated month and year -- These values return NOTHING; all of my records are from 2013, but I wanted to complete the question\n",
    "join = join[(pd.DatetimeIndex(join['OrderDate']).year == 2014) & (pd.DatetimeIndex(join['OrderDate']).month == 6)]\n",
    "\n",
    "# Create attribute OrderCount that counts the number of orders made by each Salesperson\n",
    "join['OrderCount'] = join.groupby('FullName')['CustomerName'].transform('size')\n",
    "\n",
    "# Select designated attriutes\n",
    "join[['FullName','CustomerName','CityName','OrderDate','OrderCount']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q6. List the CustomerName, CustomerCategoryName, CreditLimit, and the rank based on the highest CreditLimit within each CustomerCategory, filtered by a rank of 5 or lower. #\n",
    "\n",
    "###### PREP & JOINS #######\n",
    "\n",
    "join = cust.merge(custcat, on = 'CustomerCategoryID')\n",
    "\n",
    "# Create CreditRank attribute (na_option = bottom parameter added b/c many CreditLimit values are NULL)\n",
    "join['CreditRank'] = join.groupby('CustomerCategoryName')['CreditLimit'].rank(ascending = False, na_option = 'bottom')\n",
    "\n",
    "# Select the appropriate attributes, filter for records with a rank of 5 or lower, and sort by CategoryName and Rank\n",
    "join[['CustomerName','CustomerCategoryName','CreditLimit','CreditRank']][join['CreditRank'] <= 5].sort_values(['CustomerCategoryName','CreditRank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q7. List the SupplierName, StockItemName, OrderedOuters, ExpectedUnitPricePerOuter, # of Orders per Supplier and StockItem, # \n",
    "#     the sum of OrderedOuters per Supplier and StockItem, and the total spend per Supplier and StockItem.\n",
    "\n",
    "###### PREP & JOINS ####### - \n",
    "\n",
    "join = supp.merge(purord, on = 'SupplierID').merge(purordline, on = 'PurchaseOrderID').merge(stockit, on = 'StockItemID')\n",
    "\n",
    "# Create the 3 new attributes - (OrderCountPerSupplierAndStockID, SumOutersPerSupplierAndStockID, TotalSpendPerSupplierAndStockID)\n",
    "\n",
    "join['OrderCountPerSupplerAndStockID'] = join.groupby(['SupplierID_x','StockItemID'])['PurchaseOrderID'].transform('size')\n",
    "join['SumOutersPerSupplierAndStockID'] = join.groupby(['SupplierID_x','StockItemID'])['OrderedOuters'].transform('sum')\n",
    "\n",
    "# Created the TotalPrice (per record) attribute as a stepping stone\n",
    "join['TotalPrice'] = join['SumOutersPerSupplierAndStockID'] * join['ExpectedUnitPricePerOuter']\n",
    "# Then sum the TotalPrices of each group\n",
    "join['TotalSpendPerSupplierAndStockID'] = join.groupby(['SupplierID_x','StockItemID'])['TotalPrice'].transform('sum')\n",
    "\n",
    "# Select needed features\n",
    "join[['SupplierName','StockItemName','OrderedOuters','ExpectedUnitPricePerOuter','OrderCountPerSupplerAndStockID','SumOutersPerSupplierAndStockID','TotalSpendPerSupplierAndStockID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q8. List the CountryName, StateProvinceName, CityName, and the # of cities per country and state. # \n",
    "\n",
    "###### PREP & JOINS #######\n",
    "join = city.merge(st, on = 'StateProvinceID').merge(country, on = 'CountryID')\n",
    "\n",
    "# Create CitiesPerCountryAndState attribute\n",
    "join['CitiesPerCountryAndState'] = join.groupby(['CountryID','StateProvinceID'])['CityName'].transform('size')\n",
    "\n",
    "#Select needed features\n",
    "join[['CountryName','StateProvinceName','CityName','CitiesPerCountryAndState']].head(30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q9. List the CustomerName, StockItemName, TotalQuantity by Customer and StockItem, and the Rank of the highest Quantity per Customer and StockItem, #\n",
    "#     filtered by a rank of 5 or lower.\n",
    "\n",
    "###### PREP & JOINS #######\n",
    "join = cust.merge(orders, on = 'CustomerID').merge(ordline, on = 'OrderID').merge(stockit, on = 'StockItemID')\n",
    "\n",
    "# Create new attributes\n",
    "join['TotalQuantityByCustomerAndStockID'] = join.groupby(['CustomerID','StockItemID'])['Quantity'].transform('sum')\n",
    "join['QuantityRank'] = join.groupby('CustomerID')['TotalQuantityByCustomerAndStockID'].rank(method = 'min', ascending = False)\n",
    "\n",
    "# Select appropriate attributes and filter for rank of <= 5; sort by CustomerName and then QuantityRank\n",
    "join[['CustomerName','StockItemName','TotalQuantityByCustomerAndStockID','QuantityRank']][join['QuantityRank'] <= 5].sort_values(['CustomerName','QuantityRank'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q10. List the SupplierName, OrderYear, OrderMonth, TotalSpendBySupplier for a given Year and Month, and the rank by highest spend per month filtered #\n",
    "#      by the ‘Farbrikam, Inc.’ supplier.\n",
    "\n",
    "# I beleive I got this one right, but I doubt I took the optimal road to get there; having to use drop_duplicates() is what worries me\n",
    "\n",
    "###### PREP & JOINS #######\n",
    "join = supp.merge(purord, on = 'SupplierID').merge(purordline, on = 'PurchaseOrderID')\n",
    "\n",
    "# Create most of the required attributes - added TotalSpend as a temporary/helper attribute for creating TotalSpendPerSupplierPerMonth\n",
    "join['OrderYear'] = pd.DatetimeIndex(join['OrderDate']).year\n",
    "join['OrderMonth'] = pd.DatetimeIndex(join['OrderDate']).month\n",
    "join['TotalSpend'] = join['OrderedOuters'] * join['ExpectedUnitPricePerOuter']\n",
    "join['TotalSpendPerSupplierPerMonth'] = join.groupby(['SupplierName','OrderYear','OrderMonth'])['TotalSpend'].transform('sum')\n",
    "\n",
    "# Select the required attributes, filter to keep records with a CustomerName value containing 'Fab', drop all duplicates (created because pandas originally returns results for each individual day rather than month-year combo), and then, sort the table based on TotalSpendPerSupplierPerMonth\n",
    "\n",
    "join = join[['SupplierName','OrderYear','OrderMonth','TotalSpendPerSupplierPerMonth']][join['SupplierName'].str.contains('Fab')].drop_duplicates().sort_values('TotalSpendPerSupplierPerMonth', ascending = False)\n",
    "\n",
    "# Create the final attribute (Rank) here because it must occur after we drop duplicates and filter by CustomerName; otherwise, the ranking is thrown off by the additional records\n",
    "join['HighestSpendPerMonth'] = join['TotalSpendPerSupplierPerMonth'].rank(ascending = False)\n",
    "join\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EC1. List the OrderID, OrderDate, PickingCompleteWhen, TotalOrdersForYear, TotalOrdersForYearAndMonth, the amount of days difference #\n",
    "#      between the OrderDate and PickingCompletedWhen date, the amount of days difference between the previous column mentioned and the next slowest order.\n",
    "\n",
    "###### PREP #######\n",
    "orders_temp = orders.copy()\n",
    "\n",
    "# Create required attributes - use 'next' attribute as a stepping stone to help make 'DaysGreaterThanNextSlowest'\n",
    "orders_temp['TotalOrdersForYear'] = orders_temp.groupby(pd.DatetimeIndex(orders_temp['OrderDate']).year)['OrderID'].transform('size')\n",
    "orders_temp['TotalOrdersForYearAndMonth'] = orders_temp.groupby([(pd.DatetimeIndex(orders_temp['OrderDate']).year),(pd.DatetimeIndex(orders_temp['OrderDate']).month)])['OrderID'].transform('size')\n",
    "orders_temp['DayCountBetweenOrderAndPickup'] = (pd.to_datetime(orders_temp['PickingCompletedWhen']) - pd.to_datetime(orders_temp['OrderDate'])).dt.days\n",
    "orders_temp['next'] = orders_temp['DayCountBetweenOrderAndPickup'].shift(1)\n",
    "orders_temp['DaysGreaterThanNextSlowest'] = orders_temp['next'] - orders_temp['DayCountBetweenOrderAndPickup']\n",
    "orders_temp['MostInconvenientRanking'] = orders_temp['DayCountBetweenOrderAndPickup'].rank(ascending = False)\n",
    "\n",
    "# Select appropriate attributes\n",
    "orders_temp[['OrderID','PickingCompletedWhen','TotalOrdersForYear','TotalOrdersForYearAndMonth','DayCountBetweenOrderAndPickup','DaysGreaterThanNextSlowest','MostInconvenientRanking']]\n"
   ]
  }
 ]
}